*# Python爬虫基础教程

## 1. 什么是爬虫？

爬虫（Web Crawler）是一种自动化程序，用来模拟人类浏览网页，从互联网上批量获取数据。

## 2. 基础知识准备

- **Python基础语法**（变量、循环、函数等）
- **HTML基础**（了解标签结构）
- **常用库**：`requests`、`BeautifulSoup`

## 3. 安装必备库

在命令行输入：

```bash
pip install requests beautifulsoup4
```

## 4. 第一个爬虫示例

### 4.1 获取网页内容

```python
import requests

url = 'https://www.example.com'
response = requests.get(url)
print(response.text)  # 输出网页HTML内容
```

### 4.2 解析网页内容

```python
from bs4 import BeautifulSoup

html = response.text
soup = BeautifulSoup(html, 'html.parser')
print(soup.title.text)  # 输出网页标题
```

### 4.3 提取指定内容

假设要提取所有链接：

```python
for link in soup.find_all('a'):
    print(link.get('href'))
```

## 5. 常见问题

- **反爬虫**：有的网站会限制频繁访问，可以加请求头或延时，也可以使用代理、IP池等方式应对常见的反爬虫措施。
- **编码问题**：有时需要指定编码，如`response.encoding = 'utf-8'`。
- **数据存储**：可以用`csv`、`json`等格式保存数据。

例如，保存为CSV文件的简单示例：

## 6. 实战案例：爬取豆瓣电影Top250

```python
import requests
from bs4 import BeautifulSoup

for page in range(0, 250, 25):
    url = f'https://movie.douban.com/top250?start={page}'
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}
    response = requests.get(url, headers=headers)
        title_tag = movie.find('span', class_='title')
        if title_tag:
            print(title_tag.get_text(strip=True))
        title = movie.find('span', class_='title').text
        print(title)
```

- 尊重网站`robots.txt`协议（该文件用于声明网站允许或禁止爬虫抓取的内容，建议先查看并遵守），不要恶意爬取。可参考：[什么是robots.txt？](https://developers.google.com/search/docs/crawling-indexing/robots/intro?hl=zh-cn)

- 尊重网站`robots.txt`协议，不要恶意爬取。
- 控制访问频率，避免给网站带来压力。
- 仅用于学习和研究，勿用于商业用途。

## 8. 进阶学习

- 学习`xpath`、`selenium`等更高级的爬虫工具。
- 了解数据清洗与分析。

---

**推荐学习资源：**

- [菜鸟教程 - Python爬虫](https://www.runoob.com/python3/python3-webbug.html)
- [廖雪峰Python教程](https://www.liaoxuefeng.com/wiki/1016959663602400/1017625380741664)

祝你学习愉快，早日掌握爬虫技术！*